{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48656202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e77858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e519f0",
   "metadata": {},
   "source": [
    "# Q1:-1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "939b16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKASH JAISWAL\\AppData\\Local\\Temp\\ipykernel_248708\\1554673951.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\AKASH JAISWAL\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohith Challamalla\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71049fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23a0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Video_Name=[]\n",
    "Artist=[]\n",
    "Views=[]\n",
    "Date=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9845ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95e5b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6315b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Video_Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Video_Name.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ccd74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Bath Song\"[15]',\n",
       " '\"Shape of You\"[16]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Uptown Funk\"[24]',\n",
       " '\"Wheels on the Bus\"[25]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Sugar\"[34]',\n",
       " '\"Roar\"[35]',\n",
       " '\"Counting Stars\"[36]',\n",
       " '\"Axel F\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Dark Horse\"[41]',\n",
       " '\"Waka Waka (This Time for Africa)\"[42]',\n",
       " '\"Faded\"[43]',\n",
       " '\"Let Her Go\"[44]',\n",
       " '\"Girls Like You\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Bailando\"[47]',\n",
       " '\"Lean On\"[48]',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " '\"Lakdi Ki Kathi\"[50]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5b7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a7b68ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c564385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7e8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be0e7bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a54d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrame for scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank'] = Rank\n",
    "Wiki['Video_Name'] = Video_Name\n",
    "Wiki['Artist'] = Artist\n",
    "Wiki['Upload Date'] = Date\n",
    "Wiki['Views (in Billions)'] = Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a557bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video_Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.                          \"Wheels on the Bus\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                                     Mark Ronson  November 19, 2014   \n",
       "8                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Katy Perry  September 5, 2013   \n",
       "15                                    OneRepublic       May 31, 2013   \n",
       "16                                     Crazy Frog      June 16, 2009   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                     Katy Perry  February 20, 2014   \n",
       "21                                        Shakira       June 4, 2010   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                       Maroon 5       May 31, 2018   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29                                   Jingle Toons      June 14, 2018   \n",
       "\n",
       "   Views (in Billions)  \n",
       "0                12.00  \n",
       "1                 8.05  \n",
       "2                 6.57  \n",
       "3                 5.89  \n",
       "4                 5.88  \n",
       "5                 5.74  \n",
       "6                 5.08  \n",
       "7                 4.79  \n",
       "8                 4.77  \n",
       "9                 4.76  \n",
       "10                4.64  \n",
       "11                4.52  \n",
       "12                4.18  \n",
       "13                3.80  \n",
       "14                3.70  \n",
       "15                3.70  \n",
       "16                3.67  \n",
       "17                3.62  \n",
       "18                3.53  \n",
       "19                3.46  \n",
       "20                3.42  \n",
       "21                3.40  \n",
       "22                3.38  \n",
       "23                3.36  \n",
       "24                3.35  \n",
       "25                3.33  \n",
       "26                3.31  \n",
       "27                3.31  \n",
       "28                3.26  \n",
       "29                3.24  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b06fee",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9c6a3",
   "metadata": {},
   "source": [
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c0c0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40c21197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb82c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\AKASH JAISWAL\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f555b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fa8b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//li[@class=\"nav-item\"]').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33d98515",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[1]/div/div[1]').click()\n",
    "time.sleep(2)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f4009d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[1]/div/div[2]/div[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "988a5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeab5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "        match.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    match.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        series.append(i.text.split('-')[0])\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    place.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")\n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "        time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    time.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fba4e068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Steyn City School Ground,</td>\n",
       "      <td>2 JAN 2023</td>\n",
       "      <td>5:15 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Steyn City School Ground,</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Steyn City School Ground,</td>\n",
       "      <td>4 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Maharashtra Cricket Association Stadium,</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>7 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Eden Gardens,</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Match Title     Series  \\\n",
       "0  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19  3rd T20I    \n",
       "1  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19  4th T20I    \n",
       "2      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  1st T20I    \n",
       "3  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19  5th T20I    \n",
       "4      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  2nd T20I    \n",
       "5      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  3rd T20I    \n",
       "6      SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   1st ODI    \n",
       "7      SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   2nd ODI    \n",
       "\n",
       "                                      Venue         Date         time  \n",
       "0                 Steyn City School Ground,   2 JAN 2023  5:15 PM IST  \n",
       "1                 Steyn City School Ground,   3 JAN 2023  1:30 PM IST  \n",
       "2                         Wankhede Stadium,   3 JAN 2023  7:00 PM IST  \n",
       "3                 Steyn City School Ground,   4 JAN 2023  1:30 PM IST  \n",
       "4  Maharashtra Cricket Association Stadium,   5 JAN 2023  7:00 PM IST  \n",
       "5   Saurashtra Cricket Association Stadium,   7 JAN 2023  7:00 PM IST  \n",
       "6                Barsapara Cricket Stadium,  10 JAN 2023  1:30 PM IST  \n",
       "7                             Eden Gardens,  12 JAN 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Match Title':match,'Series':series,'Venue':place,'Date':date,'time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbc8c3",
   "metadata": {},
   "source": [
    "# Q3:-Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP(18-19) D) GSDP(17-18) E) Share(2017) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c60d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKASH JAISWAL\\AppData\\Local\\Temp\\ipykernel_248708\\1554673951.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\AKASH JAISWAL\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohith Challamalla\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec63d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://statisticstimes.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "281f5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4acd7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on India\n",
    "driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\").click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a21d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/ul/li[1]/a\").click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43d8c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4267785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    \n",
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    \n",
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00738a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Agriculture Sector</td>\n",
       "      <td>4.52</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Agriculture,forestry &amp; fishing</td>\n",
       "      <td>4.52</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>46.15</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1</td>\n",
       "      <td>Mining &amp; quarrying</td>\n",
       "      <td>18.58</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>49.63</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.3</td>\n",
       "      <td>Electricity, gas, water supply &amp; other utility...</td>\n",
       "      <td>14.26</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.4</td>\n",
       "      <td>Construction</td>\n",
       "      <td>68.33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Services Sector</td>\n",
       "      <td>11.42</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.1</td>\n",
       "      <td>Trade, hotels, transport, communication and se...</td>\n",
       "      <td>34.32</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Financial, real estate &amp; prof servs</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.3</td>\n",
       "      <td>Public Administration, defence and other services</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                              State  \\\n",
       "0     1                                 Agriculture Sector   \n",
       "1   1.1                     Agriculture,forestry & fishing   \n",
       "2     2                                    Industry Sector   \n",
       "3   2.1                                 Mining & quarrying   \n",
       "4   2.2                                      Manufacturing   \n",
       "5   2.3  Electricity, gas, water supply & other utility...   \n",
       "6   2.4                                       Construction   \n",
       "7     3                                    Services Sector   \n",
       "8   3.1  Trade, hotels, transport, communication and se...   \n",
       "9   3.2                Financial, real estate & prof servs   \n",
       "10  3.3  Public Administration, defence and other services   \n",
       "\n",
       "   GSDP at current price (19-20) GSDP at current price (18-19) Share (18-19)  \\\n",
       "0                           4.52                             -             -   \n",
       "1                           4.52                             -             -   \n",
       "2                          46.15                             -             -   \n",
       "3                          18.58                             -             -   \n",
       "4                          49.63                             -             -   \n",
       "5                          14.26                             -             -   \n",
       "6                          68.33                             -             -   \n",
       "7                          11.42                             -             -   \n",
       "8                          34.32                             -             -   \n",
       "9                           3.69                             -             -   \n",
       "10                          5.81                             -             -   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0               -  \n",
       "1               -  \n",
       "2               -  \n",
       "3               -  \n",
       "4               -  \n",
       "5               -  \n",
       "6               -  \n",
       "7               -  \n",
       "8               -  \n",
       "9               -  \n",
       "10              -  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share (18-19)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52690842",
   "metadata": {},
   "source": [
    "# Q-4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ff80d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d3bac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting explore button and clicking on it\n",
    "explore = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[1]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28d776c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting trending option\n",
    "trend_url = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\")\n",
    "urls = trend_url.get_attribute(\"href\")\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b003c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26b4f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "# scraping Repository title data\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)\n",
    "    \n",
    "# scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # scraping Repository Description data \n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,\"//p[@class='f4 mt-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "    \n",
    "    \n",
    "    # scraping Languages used data\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"//ul[@class= 'list-style-none']//li//span[1]\"):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5affd288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAION-AI / Open-Assistant</td>\n",
       "      <td>-</td>\n",
       "      <td>21</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple / ml-stable-diffusion</td>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hehonghui / awesome-english-ebooks</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmruthPillai / Reactive-Resume</td>\n",
       "      <td>-</td>\n",
       "      <td>84</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microfeed / microfeed</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>excalidraw / excalidraw</td>\n",
       "      <td>-</td>\n",
       "      <td>211</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TheOfficialFloW / HENlo</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tesseract-ocr / tesseract</td>\n",
       "      <td>-</td>\n",
       "      <td>158</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zhuowei / WDBFontOverwrite</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>novuhq / novu</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>timqian / chinese-independent-blogs</td>\n",
       "      <td>-</td>\n",
       "      <td>851</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gabiduarte / awesome-techleads</td>\n",
       "      <td>-</td>\n",
       "      <td>17</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>microsoft / RoadDetections</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lencx / ChatGPT</td>\n",
       "      <td>-</td>\n",
       "      <td>7</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>-</td>\n",
       "      <td>695</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mouredev / retos-programacion-2023</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AmazingAng / WTF-Solidity</td>\n",
       "      <td>-</td>\n",
       "      <td>73</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zas023 / JdBuyer</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ChatGPT-Hackers / ChatGPT-API-server</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bregman-arie / devops-resources</td>\n",
       "      <td>-</td>\n",
       "      <td>19</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zinclabs / zinc</td>\n",
       "      <td>-</td>\n",
       "      <td>34</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>google / comprehensive-rust</td>\n",
       "      <td>-</td>\n",
       "      <td>23</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>521xueweihan / HelloGitHub</td>\n",
       "      <td>-</td>\n",
       "      <td>11</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai-php / laravel</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>malkemit / namizun</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>[, open-assistant/oasst-backend, , open-assist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Repository title Repository description  \\\n",
       "0              LAION-AI / Open-Assistant                      -   \n",
       "1            apple / ml-stable-diffusion                      -   \n",
       "2     hehonghui / awesome-english-ebooks                      -   \n",
       "3         AmruthPillai / Reactive-Resume                      -   \n",
       "4                  microfeed / microfeed                      -   \n",
       "5                excalidraw / excalidraw                      -   \n",
       "6                TheOfficialFloW / HENlo                      -   \n",
       "7              tesseract-ocr / tesseract                      -   \n",
       "8             zhuowei / WDBFontOverwrite                      -   \n",
       "9                          novuhq / novu                      -   \n",
       "10   timqian / chinese-independent-blogs                      -   \n",
       "11        gabiduarte / awesome-techleads                      -   \n",
       "12            microsoft / RoadDetections                      -   \n",
       "13                       lencx / ChatGPT                      -   \n",
       "14                      facebook / folly                      -   \n",
       "15    mouredev / retos-programacion-2023                      -   \n",
       "16             AmazingAng / WTF-Solidity                      -   \n",
       "17                      zas023 / JdBuyer                      -   \n",
       "18  ChatGPT-Hackers / ChatGPT-API-server                      -   \n",
       "19       bregman-arie / devops-resources                      -   \n",
       "20                       zinclabs / zinc                      -   \n",
       "21           google / comprehensive-rust                      -   \n",
       "22            521xueweihan / HelloGitHub                      -   \n",
       "23                  openai-php / laravel                      -   \n",
       "24                    malkemit / namizun                      -   \n",
       "\n",
       "   Contributors count                                      Language used  \n",
       "0                  21  [, open-assistant/oasst-backend, , open-assist...  \n",
       "1                  11  [, open-assistant/oasst-backend, , open-assist...  \n",
       "2                   -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "3                  84  [, open-assistant/oasst-backend, , open-assist...  \n",
       "4                   -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "5                 211  [, open-assistant/oasst-backend, , open-assist...  \n",
       "6                   -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "7                 158  [, open-assistant/oasst-backend, , open-assist...  \n",
       "8                   -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "9                 232  [, open-assistant/oasst-backend, , open-assist...  \n",
       "10                851  [, open-assistant/oasst-backend, , open-assist...  \n",
       "11                 17  [, open-assistant/oasst-backend, , open-assist...  \n",
       "12                  4  [, open-assistant/oasst-backend, , open-assist...  \n",
       "13                  7  [, open-assistant/oasst-backend, , open-assist...  \n",
       "14                695  [, open-assistant/oasst-backend, , open-assist...  \n",
       "15                  -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "16                 73  [, open-assistant/oasst-backend, , open-assist...  \n",
       "17                  -  [, open-assistant/oasst-backend, , open-assist...  \n",
       "18                  5  [, open-assistant/oasst-backend, , open-assist...  \n",
       "19                 19  [, open-assistant/oasst-backend, , open-assist...  \n",
       "20                 34  [, open-assistant/oasst-backend, , open-assist...  \n",
       "21                 23  [, open-assistant/oasst-backend, , open-assist...  \n",
       "22                 11  [, open-assistant/oasst-backend, , open-assist...  \n",
       "23                  4  [, open-assistant/oasst-backend, , open-assist...  \n",
       "24                  4  [, open-assistant/oasst-backend, , open-assist...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Github_df=pd.DataFrame({})\n",
    "Github_df['Repository title'] = repository_title\n",
    "Github_df['Repository description'] = Description\n",
    "Github_df['Contributors count'] = Contributors\n",
    "Github_df['Language used'] = Language\n",
    "Github_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ebce68",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billboard.com. Url = https://www.billboard.com/ You have to find the following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5562a",
   "metadata": {},
   "source": [
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac385b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41983f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\AKASH JAISWAL\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9728c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the specified url\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fffa9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "050b2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a\")\n",
    "view.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8f30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = []\n",
    "artist = []\n",
    "last = []\n",
    "peak = []\n",
    "weeks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1136cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//li//ul//li[1]/h3'):\n",
    "    song.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//li//ul//li[1]/span'):\n",
    "    artist.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//li//ul//li[4]/span'):\n",
    "    last.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//li//ul//li[5]/span'):\n",
    "    peak.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//ul//li//ul//li[6]/span'):\n",
    "    weeks.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7422c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 200 200 100\n"
     ]
    }
   ],
   "source": [
    "print(len(artist),len(song),len(last),len(peak),len(weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc41ffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last Christmas</td>\n",
       "      <td>Wham!</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Down Home</td>\n",
       "      <td>Jimmie Allen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>One Thing At A Time</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hold Me Closer</td>\n",
       "      <td>Elton John &amp; Britney Spears</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Far</td>\n",
       "      <td>SZA</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>All Mine</td>\n",
       "      <td>Brent Faiyaz</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song Name                  Artist Name  \\\n",
       "0     All I Want For Christmas Is You                 Mariah Carey   \n",
       "1   Rockin' Around The Christmas Tree                   Brenda Lee   \n",
       "2                    Jingle Bell Rock                  Bobby Helms   \n",
       "3             A Holly Jolly Christmas                    Burl Ives   \n",
       "4                      Last Christmas                        Wham!   \n",
       "..                                ...                          ...   \n",
       "95                          Down Home                 Jimmie Allen   \n",
       "96                One Thing At A Time                Morgan Wallen   \n",
       "97                     Hold Me Closer  Elton John & Britney Spears   \n",
       "98                                Far                          SZA   \n",
       "99                           All Mine                 Brent Faiyaz   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0               1         1             57  \n",
       "1                                       51  \n",
       "2               2         2             48  \n",
       "3                                       31  \n",
       "4               4         3             30  \n",
       "..            ...       ...            ...  \n",
       "95                                       5  \n",
       "96              -        37              3  \n",
       "97                                      17  \n",
       "98             53        12              2  \n",
       "99                                      20  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard = pd.DataFrame({'Song Name':song,'Artist Name':artist,'Last Week Rank':last[:100],'Peak Rank':peak[:100],'Weeks on Board':weeks})\n",
    "billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082ed75",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b95662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f602feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKASH JAISWAL\\AppData\\Local\\Temp\\ipykernel_212460\\1554673951.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\AKASH JAISWAL\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohith Challamalla\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ec427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ac1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c2ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea1e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b668538",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08c47341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14825a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c9aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ae2c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,098,621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,188,737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>993,396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>293,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>253,124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>199,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>246,696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,098,621  \n",
       "1    51 min     8.7  1,188,737  \n",
       "2    44 min     8.1    993,396  \n",
       "3    60 min     7.5    293,977  \n",
       "4    43 min     7.6    253,124  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,343  \n",
       "96   50 min     7.8     61,903  \n",
       "97   42 min     8.1    199,720  \n",
       "98   45 min     7.1     41,693  \n",
       "99  572 min     8.6    246,696  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Genre'] = Genre\n",
    "TV_Series['Run Time'] = Run_time\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de4951",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de16417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dad0278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Rohith Challamalla\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff18370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/index.php\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25362c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewdataset = driver.find_element(By.XPATH,'//tbody/tr/td[2]/span[2]/a')\n",
    "page_url = viewdataset.get_attribute('href')\n",
    "driver.get(page_url)\n",
    "time.sleep(5)\n",
    "\n",
    "all_lst = driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "lst_url = all_lst.get_attribute(\"href\")           \n",
    "driver.get(lst_url)\n",
    "time.sleep(5)\n",
    "\n",
    "data_url = driver.find_elements(By.XPATH,\"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in data_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2817c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attr_type = []\n",
    "Instances = []\n",
    "n_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77fa7d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m      2\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(i)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m      8\u001b[0m         ds_name \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//span[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheading\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "\n",
    "    try: \n",
    "        ds_name = driver.find_element(By.XPATH,\"//span[@class='heading']\")\n",
    "        Data_name.append(ds_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_name.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dtype = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if dtype.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(dtype.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        atype = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if atype.text == \"N/A\": raise NoSuchElementException\n",
    "        Attr_type.append(atype.text)\n",
    "    except NoSuchElementException:\n",
    "        Attr_type.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "     \n",
    "    try:\n",
    "        inst = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if inst.text == \"N/A\": raise NoSuchElementException\n",
    "        Instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        attr = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attr.text == \"N/A\": raise NoSuchElementException\n",
    "        n_attributes.append(attr.text)\n",
    "    except NoSuchElementException:\n",
    "        n_attributes.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9960418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A study of Asian Religious and Biblical Texts ...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer</td>\n",
       "      <td>590</td>\n",
       "      <td>8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAAI 2013 Accepted Papers Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAAI 2014 Accepted Papers Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>399</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abscisic Acid Signaling Network Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Causal-Discovery</td>\n",
       "      <td>Integer</td>\n",
       "      <td>300</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Absenteeism at work Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>740</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Accelerometer Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>153000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Activities of Daily Living (ADLs) Recognition ...</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>2747</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Activity Recognition from Single Chest-Mounted...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Activity Recognition system based on Multisens...</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>42240</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Activity recognition using wearable physiologi...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>4480</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Activity recognition with healthy older people...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>75128</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Acute Inflammations Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI4I 2020 Predictive Maintenance Dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Regression, Causal-Discovery</td>\n",
       "      <td>Real</td>\n",
       "      <td>10000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A study of Asian Religious and Biblical Texts ...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer</td>\n",
       "      <td>590</td>\n",
       "      <td>8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AAAI 2013 Accepted Papers Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AAAI 2014 Accepted Papers Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>399</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Abscisic Acid Signaling Network Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Causal-Discovery</td>\n",
       "      <td>Integer</td>\n",
       "      <td>300</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Absenteeism at work Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>740</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Accelerometer Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>153000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Activities of Daily Living (ADLs) Recognition ...</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>2747</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Activity Recognition from Single Chest-Mounted...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Activity Recognition system based on Multisens...</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>42240</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Activity recognition using wearable physiologi...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>4480</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Activity recognition with healthy older people...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>75128</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Acute Inflammations Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AI4I 2020 Predictive Maintenance Dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Regression, Causal-Discovery</td>\n",
       "      <td>Real</td>\n",
       "      <td>10000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Air Quality Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>9358</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Air Quality Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>9358</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Airfoil Self-Noise Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>1503</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Alcohol QCM Sensor Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>125</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Algerian Forest Fires Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>244</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Amazon Access Samples Data Set</td>\n",
       "      <td>Time-Series, Domain-Theory</td>\n",
       "      <td>Regression, Clustering, Causal-Discovery</td>\n",
       "      <td>-</td>\n",
       "      <td>30000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Amazon Commerce reviews set Data Set</td>\n",
       "      <td>Multivariate, Text, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>1500</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amphibians Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>189</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Annealing Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Anonymous Microsoft Web Data Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Anticancer peptides Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Anuran Calls (MFCCs) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>7195</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Apartment for rent classified Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>10000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Appliances energy prediction Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>19735</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>APS Failure at Scania Trucks Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>60000</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Arcene Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>900</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Arrhythmia Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Data Name  \\\n",
       "0        2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1   3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                 3W dataset Data Set   \n",
       "3                         9mers from cullpdb Data Set   \n",
       "4   : Simulated Data set of Iraqi tourism places D...   \n",
       "5   A study of Asian Religious and Biblical Texts ...   \n",
       "6                  AAAI 2013 Accepted Papers Data Set   \n",
       "7                  AAAI 2014 Accepted Papers Data Set   \n",
       "8                                    Abalone Data Set   \n",
       "9            Abscisic Acid Signaling Network Data Set   \n",
       "10                       Absenteeism at work Data Set   \n",
       "11                             Accelerometer Data Set   \n",
       "12  Activities of Daily Living (ADLs) Recognition ...   \n",
       "13  Activity Recognition from Single Chest-Mounted...   \n",
       "14  Activity Recognition system based on Multisens...   \n",
       "15  Activity recognition using wearable physiologi...   \n",
       "16  Activity recognition with healthy older people...   \n",
       "17                       Acute Inflammations Data Set   \n",
       "18                                     Adult Data Set   \n",
       "19  AI4I 2020 Predictive Maintenance Dataset Data Set   \n",
       "20       2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "21  3D Road Network (North Jutland, Denmark) Data Set   \n",
       "22                                3W dataset Data Set   \n",
       "23                        9mers from cullpdb Data Set   \n",
       "24  : Simulated Data set of Iraqi tourism places D...   \n",
       "25  A study of Asian Religious and Biblical Texts ...   \n",
       "26                 AAAI 2013 Accepted Papers Data Set   \n",
       "27                 AAAI 2014 Accepted Papers Data Set   \n",
       "28                                   Abalone Data Set   \n",
       "29           Abscisic Acid Signaling Network Data Set   \n",
       "30                       Absenteeism at work Data Set   \n",
       "31                             Accelerometer Data Set   \n",
       "32  Activities of Daily Living (ADLs) Recognition ...   \n",
       "33  Activity Recognition from Single Chest-Mounted...   \n",
       "34  Activity Recognition system based on Multisens...   \n",
       "35  Activity recognition using wearable physiologi...   \n",
       "36  Activity recognition with healthy older people...   \n",
       "37                       Acute Inflammations Data Set   \n",
       "38                                     Adult Data Set   \n",
       "39  AI4I 2020 Predictive Maintenance Dataset Data Set   \n",
       "40                               Air Quality Data Set   \n",
       "41                               Air Quality Data Set   \n",
       "42                        Airfoil Self-Noise Data Set   \n",
       "43                Alcohol QCM Sensor Dataset Data Set   \n",
       "44             Algerian Forest Fires Dataset Data Set   \n",
       "45                     Amazon Access Samples Data Set   \n",
       "46               Amazon Commerce reviews set Data Set   \n",
       "47                                Amphibians Data Set   \n",
       "48                                 Annealing Data Set   \n",
       "49              Anonymous Microsoft Web Data Data Set   \n",
       "50                       Anticancer peptides Data Set   \n",
       "51                      Anuran Calls (MFCCs) Data Set   \n",
       "52             Apartment for rent classified Data Set   \n",
       "53              Appliances energy prediction Data Set   \n",
       "54              APS Failure at Scania Trucks Data Set   \n",
       "55                                    Arcene Data Set   \n",
       "56                                Arrhythmia Data Set   \n",
       "\n",
       "                                Data Type  \\\n",
       "0                            Multivariate   \n",
       "1                        Sequential, Text   \n",
       "2               Multivariate, Time-Series   \n",
       "3                              Sequential   \n",
       "4                            Multivariate   \n",
       "5                      Multivariate, Text   \n",
       "6                            Multivariate   \n",
       "7                            Multivariate   \n",
       "8                            Multivariate   \n",
       "9                            Multivariate   \n",
       "10              Multivariate, Time-Series   \n",
       "11                           Multivariate   \n",
       "12  Multivariate, Sequential, Time-Series   \n",
       "13    Univariate, Sequential, Time-Series   \n",
       "14  Multivariate, Sequential, Time-Series   \n",
       "15                           Multivariate   \n",
       "16                             Sequential   \n",
       "17                           Multivariate   \n",
       "18                           Multivariate   \n",
       "19              Multivariate, Time-Series   \n",
       "20                           Multivariate   \n",
       "21                       Sequential, Text   \n",
       "22              Multivariate, Time-Series   \n",
       "23                             Sequential   \n",
       "24                           Multivariate   \n",
       "25                     Multivariate, Text   \n",
       "26                           Multivariate   \n",
       "27                           Multivariate   \n",
       "28                           Multivariate   \n",
       "29                           Multivariate   \n",
       "30              Multivariate, Time-Series   \n",
       "31                           Multivariate   \n",
       "32  Multivariate, Sequential, Time-Series   \n",
       "33    Univariate, Sequential, Time-Series   \n",
       "34  Multivariate, Sequential, Time-Series   \n",
       "35                           Multivariate   \n",
       "36                             Sequential   \n",
       "37                           Multivariate   \n",
       "38                           Multivariate   \n",
       "39              Multivariate, Time-Series   \n",
       "40              Multivariate, Time-Series   \n",
       "41              Multivariate, Time-Series   \n",
       "42                           Multivariate   \n",
       "43                           Multivariate   \n",
       "44                           Multivariate   \n",
       "45             Time-Series, Domain-Theory   \n",
       "46      Multivariate, Text, Domain-Theory   \n",
       "47                           Multivariate   \n",
       "48                           Multivariate   \n",
       "49                                      -   \n",
       "50                             Sequential   \n",
       "51                           Multivariate   \n",
       "52                           Multivariate   \n",
       "53              Multivariate, Time-Series   \n",
       "54                           Multivariate   \n",
       "55                           Multivariate   \n",
       "56                           Multivariate   \n",
       "\n",
       "                                            Task              Attribute type  \\\n",
       "0                                 Classification                        Real   \n",
       "1                         Regression, Clustering                        Real   \n",
       "2                     Classification, Clustering               Integer, Real   \n",
       "3                     Classification, Regression                        Real   \n",
       "4                     Classification, Clustering                           -   \n",
       "5                     Classification, Clustering                     Integer   \n",
       "6                                     Clustering                           -   \n",
       "7                                     Clustering                           -   \n",
       "8                                 Classification  Categorical, Integer, Real   \n",
       "9                               Causal-Discovery                     Integer   \n",
       "10                    Classification, Clustering               Integer, Real   \n",
       "11                    Classification, Regression               Integer, Real   \n",
       "12                    Classification, Clustering                           -   \n",
       "13                    Classification, Clustering                        Real   \n",
       "14                                Classification                        Real   \n",
       "15                                Classification                        Real   \n",
       "16                                Classification                        Real   \n",
       "17                                Classification        Categorical, Integer   \n",
       "18                                Classification        Categorical, Integer   \n",
       "19  Classification, Regression, Causal-Discovery                        Real   \n",
       "20                                Classification                        Real   \n",
       "21                        Regression, Clustering                        Real   \n",
       "22                    Classification, Clustering               Integer, Real   \n",
       "23                    Classification, Regression                        Real   \n",
       "24                    Classification, Clustering                           -   \n",
       "25                    Classification, Clustering                     Integer   \n",
       "26                                    Clustering                           -   \n",
       "27                                    Clustering                           -   \n",
       "28                                Classification  Categorical, Integer, Real   \n",
       "29                              Causal-Discovery                     Integer   \n",
       "30                    Classification, Clustering               Integer, Real   \n",
       "31                    Classification, Regression               Integer, Real   \n",
       "32                    Classification, Clustering                           -   \n",
       "33                    Classification, Clustering                        Real   \n",
       "34                                Classification                        Real   \n",
       "35                                Classification                        Real   \n",
       "36                                Classification                        Real   \n",
       "37                                Classification        Categorical, Integer   \n",
       "38                                Classification        Categorical, Integer   \n",
       "39  Classification, Regression, Causal-Discovery                        Real   \n",
       "40                                    Regression                        Real   \n",
       "41                                    Regression                        Real   \n",
       "42                                    Regression                        Real   \n",
       "43        Classification, Regression, Clustering                        Real   \n",
       "44                    Classification, Regression                        Real   \n",
       "45      Regression, Clustering, Causal-Discovery                           -   \n",
       "46                                Classification                        Real   \n",
       "47                                Classification               Integer, Real   \n",
       "48                                Classification  Categorical, Integer, Real   \n",
       "49                           Recommender-Systems                 Categorical   \n",
       "50                                Classification                           -   \n",
       "51                    Classification, Clustering                        Real   \n",
       "52        Classification, Regression, Clustering                           -   \n",
       "53                                    Regression                        Real   \n",
       "54                                Classification               Integer, Real   \n",
       "55                                Classification                        Real   \n",
       "56                                Classification  Categorical, Integer, Real   \n",
       "\n",
       "   No of instance No of attributes  \n",
       "0            7840                5  \n",
       "1          434874                4  \n",
       "2            1984                8  \n",
       "3          158716                4  \n",
       "4             232               16  \n",
       "5             590             8265  \n",
       "6             150                5  \n",
       "7             399                6  \n",
       "8            4177                8  \n",
       "9             300               43  \n",
       "10            740               21  \n",
       "11         153000                5  \n",
       "12           2747                -  \n",
       "13              -                -  \n",
       "14          42240                6  \n",
       "15           4480              533  \n",
       "16          75128                9  \n",
       "17            120                6  \n",
       "18          48842               14  \n",
       "19          10000               14  \n",
       "20           7840                5  \n",
       "21         434874                4  \n",
       "22           1984                8  \n",
       "23         158716                4  \n",
       "24            232               16  \n",
       "25            590             8265  \n",
       "26            150                5  \n",
       "27            399                6  \n",
       "28           4177                8  \n",
       "29            300               43  \n",
       "30            740               21  \n",
       "31         153000                5  \n",
       "32           2747                -  \n",
       "33              -                -  \n",
       "34          42240                6  \n",
       "35           4480              533  \n",
       "36          75128                9  \n",
       "37            120                6  \n",
       "38          48842               14  \n",
       "39          10000               14  \n",
       "40           9358               15  \n",
       "41           9358               15  \n",
       "42           1503                6  \n",
       "43            125                8  \n",
       "44            244               12  \n",
       "45          30000            20000  \n",
       "46           1500            10000  \n",
       "47            189               23  \n",
       "48            798               38  \n",
       "49          37711              294  \n",
       "50           1850                2  \n",
       "51           7195               22  \n",
       "52          10000               22  \n",
       "53          19735               29  \n",
       "54          60000              171  \n",
       "55            900            10000  \n",
       "56            452              279  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI=pd.DataFrame({})\n",
    "UCI['Data Name'] = Data_name\n",
    "UCI['Data Type'] = Data_type\n",
    "UCI['Task'] = Task\n",
    "UCI['Attribute type'] = Attr_type\n",
    "UCI['No of instance'] = Instances\n",
    "UCI['No of attributes'] = n_attributes\n",
    "\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a0728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
